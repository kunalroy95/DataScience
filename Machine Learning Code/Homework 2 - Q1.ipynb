{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_classifier(x, D, K, labels, measure):\n",
    "\n",
    "    if measure == 0:\n",
    "        # euclidean distances from the other points\n",
    "        dists = np.sqrt(((D - x)**2).sum(axis=1))\n",
    "    elif measure == 1:\n",
    "        # first find the vector norm for each instance in D as wel as the norm for vector x\n",
    "        D_norm = np.array([np.linalg.norm(D[i]) for i in range(len(D))])\n",
    "        x_norm = np.linalg.norm(x)\n",
    "        # Compute Cosine: divide the dot product o x and each instance in D by the product of the two norms\n",
    "        sims = np.dot(D,x)/(D_norm * x_norm)\n",
    "        # The distance measure will be the inverse of Cosine similarity\n",
    "        dists = 1 - sims\n",
    "    idx = np.argsort(dists) # sorting\n",
    "    \n",
    "    classCount={}\n",
    "    for i in range(K):\n",
    "        voteIlabel = labels[idx[i]]\n",
    "        classCount[voteIlabel] = classCount.get(voteIlabel,0) + 1 # add to the count of the label or retun 1 for first occu\n",
    "        sortedClassCount = sorted(classCount.items(), key=operator.itemgetter(1), reverse=True)\n",
    "    return sortedClassCount[0][0], idx[:K]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification_accurcay(target, x, D, K, lablels, measure):\n",
    "    num_traget = len(target)\n",
    "    errorCount = 0.0\n",
    "    for i in range(num_target):\n",
    "    \n",
    "        classifierResult, neighbors = knn_classifier(x[i,:], D, K, labels, measure)\n",
    "        if (classifierResult != target[i]): errorCount += 1.0\n",
    "    \n",
    "    error_rate = errorCount/float(num_target)\n",
    "    \n",
    "    return error_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = np.genfromtxt('trainMatrixModified.txt', delimiter='\\t', dtype = float)\n",
    "training_transposed = training.T\n",
    "\n",
    "labels = np.genfromtxt('trainClasses.txt', delimiter='\\t', usecols = (1), dtype = int)\n",
    "\n",
    "\n",
    "testing = np.genfromtxt('testMatrixModified.txt', delimiter='\\t', dtype = float)\n",
    "testing_transposed = testing.T\n",
    "\n",
    "test_labels = np.genfromtxt('testClasses.txt', delimiter='\\t', usecols = (1), dtype = int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table\n",
      " K  Euclidian  Cosine\n",
      " 1   0.22    0.01\n",
      " 2   0.22    0.01\n",
      " 3   0.19    0.03\n",
      " 4   0.19    0.01\n",
      " 5   0.18    0.03\n",
      " 6   0.17    0.01\n",
      " 7   0.23    0.02\n",
      " 8   0.20    0.02\n",
      " 9   0.25    0.03\n",
      "10   0.15    0.01\n",
      "11   0.20    0.02\n",
      "12   0.15    0.03\n",
      "13   0.23    0.02\n",
      "14   0.18    0.02\n",
      "15   0.21    0.01\n",
      "16   0.20    0.02\n",
      "17   0.24    0.03\n",
      "18   0.21    0.03\n",
      "19   0.26    0.03\n",
      "20   0.23    0.03\n"
     ]
    }
   ],
   "source": [
    "table = np.zeros((20,3), dtype=float)\n",
    "for i in range(0,20):\n",
    "    error_rate_euc = classification_accuracy(test_labels, testing_transposed, training_transposed, i+1, labels, 0)\n",
    "    error_rate_cos = classification_accuracy(test_labels, testing_transposed, training_transposed, i+1, labels, 1)\n",
    "    table[i] = [i+1, error_rate_euc, error_rate_cos]\n",
    "    \n",
    "print(\"Table\")\n",
    "print(\" K  Euclidian  Cosine\")\n",
    "for row in table:\n",
    "   print(\"%2.0f   %.2f    %.2f\" % (row[0], row[1], row[2]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = np.concatenate((training, testing), axis=1)\n",
    "array = pd.DataFrame([(combined!=0).sum(1)]).T\n",
    "NDocs = combined.shape[1]\n",
    "NMatrix=np.ones(np.shape(combined), dtype=float)*NDocs\n",
    "IDF = np.log2(np.divide(NMatrix, np.array(array)))\n",
    "TD_tfidf = combined * IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "transposed_tfidf = TD_tfidf.T\n",
    "\n",
    "train_tfidf, test_tfidf = train_test_split(transposed_tfidf, test_size=0.20, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table for TF-IDF Matrix:\n",
      " K  Euclidian  Cosine\n",
      " 1   0.46    0.48\n",
      " 2   0.46    0.48\n",
      " 3   0.45    0.47\n",
      " 4   0.44    0.51\n",
      " 5   0.47    0.53\n",
      " 6   0.48    0.48\n",
      " 7   0.51    0.46\n",
      " 8   0.51    0.48\n",
      " 9   0.51    0.51\n",
      "10   0.53    0.50\n",
      "11   0.49    0.55\n",
      "12   0.45    0.53\n",
      "13   0.48    0.52\n",
      "14   0.50    0.51\n",
      "15   0.52    0.55\n",
      "16   0.52    0.55\n",
      "17   0.55    0.54\n",
      "18   0.55    0.55\n",
      "19   0.54    0.51\n",
      "20   0.52    0.52\n"
     ]
    }
   ],
   "source": [
    "table1 = np.zeros((20,3), dtype=float)\n",
    "for i in range(0,20):\n",
    "    error_rate_euc = classification_accuracy(test_labels, test_tfidf, train_tfidf, i+1, labels, 0)\n",
    "    error_rate_cos = classification_accuracy(test_labels, test_tfidf, train_tfidf, i+1, labels, 1)\n",
    "    table1[i] = [i+1, error_rate_euc, error_rate_cos]\n",
    "    \n",
    "print(\"Table for TF-IDF Matrix:\")\n",
    "print(\" K  Euclidian  Cosine\")\n",
    "for row in table1:\n",
    "   print(\"%2.0f   %.2f    %.2f\" % (row[0], row[1], row[2]) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The error rates when using the TF-IDF matrix are much higher than when not using it for both the euclidian and cosine distance measures. Therefore I would go with the non-TFIDF matrix for this problem as they are giving much lower error rates, also specifically I would go with the cosine similarity method as that is giving the lowest error rates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
